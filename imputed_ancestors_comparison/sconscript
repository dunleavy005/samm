## Test model fits against one another

import os
import pickle
import csv
import numpy as np

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
from matsen_grp_data import SCRATCH_DIR, CUI_DATA_PATH
from hier_motif_feature_generator import HierarchicalMotifFeatureGenerator
from itertools import izip
from common import pick_best_model
from context_model_algo import *

Import('env')
localenv = env.Clone()

# Set up state
base = {'nreps': localenv['NREPS'],
        'output_name': localenv['OUTPUT_NAME']}

nest = SConsWrap(Nest(base_dict=base), '_'+localenv['OUTPUT_NAME'], alias_environment=localenv)

MOTIF_LEN = 5
MUTATING_POSITION = 2
N_CLONAL_FAMILIES = 1500
PENALTY_PARAMS = ",".join(map(str, np.power(10, np.arange(-2.0, -7.0, step=-0.25)).tolist()))
MUTABILITY_PATH = 'gctree/S5F/Mutability.csv'
SUBSTITUTION_PATH = 'gctree/S5F/Substitution.csv'

# Nest for replicates
nest.add(
    'replicate',
    range(localenv['NREPS']),
    label_func='{:02d}'.format)

# Set the seed to be the replicate number.
nest.add(
    'seed',
    lambda c: [c['replicate']],
    create_dir=False)

@nest.add_target_with_env(localenv)
def generate_theta(env, outdir, c):
    cmd = ['python generate_theta.py',
           '--mutability',
           MUTABILITY_PATH,
           '--substitution',
           SUBSTITUTION_PATH,
           '--motif-lens',
           MOTIF_LEN,
           '--positions-mutating',
           MUTATING_POSITION,
           '--use-shmulate-as-truth',
           '--per-target-model',
           '--output-model ${TARGETS[0]}']

    return env.Command(
        [join(outdir, 'true_theta.pkl')],
        [],
        ' '.join(map(str, cmd)))

# Targets for simulating fake data
@nest.add_target_with_env(localenv)
def generate_seqs(env, outdir, c):
    generate_cmd = ['python simulate_from_sampled_gls.py simulate',
           '--seed',
           c['seed'],
           '--mutability',
           MUTABILITY_PATH,
           '--substitution',
           SUBSTITUTION_PATH,
           '--use-v',
           '--use-immunized',
           '--use-partis',
           '--locus',
           'igk',
           '--path-to-annotations',
           CUI_DATA_PATH,
            '--path-to-metadata',
           CUI_DATA_PATH + '/meta.csv',
           '--motif-lens',
           MOTIF_LEN,
           '--n-clonal-families',
           N_CLONAL_FAMILIES,
           '--output-germline-seqs ${TARGETS[0]}',
           '--output-seqs ${TARGETS[1]}',
           '--output-per-branch-germline-seqs ${TARGETS[2]}',
           '--output-per-branch-seqs ${TARGETS[3]}']

    process_cmd = ['python preprocess_data.py',
           '--input-genes ${TARGETS[0]}',
           '--input-seqs ${TARGETS[1]}',
           '--motif-len',
           MOTIF_LEN,
           '--impute-ancestors',
           '--sample-from-family',
           '--scratch-directory',
           SCRATCH_DIR,
           '--output-genes-imputed ${TARGETS[4]}',
           '--output-seqs-imputed ${TARGETS[5]}',
           '--output-genes-sampled ${TARGETS[6]}',
           '--output-seqs-sampled ${TARGETS[7]}']

    cmd = generate_cmd + ['&&'] + process_cmd

    return env.Command(
        [join(outdir, 'genes.csv'), join(outdir, 'seqs.csv'),
         join(outdir, 'genes_with_ancestors.csv'), join(outdir, 'seqs_with_ancestors.csv'),
         join(outdir, 'genes_with_imputed_ancestors.csv'), join(outdir, 'seqs_with_imputed_ancestors.csv'),
         join(outdir, 'genes_sampled.csv'), join(outdir, 'seqs_sampled.csv')],
        [],
        ' '.join(map(str, cmd)))

def write_truth(target, source, env):
    c = env['control']
    with open(str(source[0]), 'r') as f:
        theta_mut, theta_sub = pickle.load(f)

    feat_generator = HierarchicalMotifFeatureGenerator(motif_lens=[MOTIF_LEN])
    motif_list = feat_generator.motif_list

    columns = 'rep motif col theta model'.split()
    data = []
    for col in range(5):
        for idx, motif in enumerate(motif_list):
            data_dict = {'rep': c['replicate'], 'motif': motif, 'col': col, 'model': 'truth'}
            if col == 0:
                data_dict['theta'] = theta_mut.ravel()[idx]
            else:
                data_dict['theta'] = theta_sub[idx, col - 1]

            data.append(data_dict)

    with open(str(target[0]), 'wb') as f:
        writer = csv.DictWriter(f, columns)
        writer.writeheader()
        writer.writerows(data)

@nest.add_target_with_env(localenv)
def convert_truth(env, outdir, c):
    return env.Command(
        join(outdir, 'true_theta.csv'),
        c['generate_theta'],
        write_truth,
        control=c)

nest.add_aggregate('compare_models', list)

nest.add(
    'data_type',
    [
        'true_ancestors',
        'imputed_ancestors',
        'all_data',
        'sample_random',
    ])

@nest.add_target_with_env(localenv)
def fit_shazam(env, outdir, c):

    cmd = ['python fit_shmulate_model.py',
           '--model-pkl ${TARGETS[0]}',
           '--log-file ${TARGETS[1]}',
           '--center-median']

    if c['data_type'] == 'true_ancestors':
        cmd += ['--input-genes ${SOURCES[2]} --input-file ${SOURCES[3]}']
    elif c['data_type'] == 'imputed_ancestors':
        cmd += ['--input-genes ${SOURCES[4]} --input-file ${SOURCES[5]}']
    elif c['data_type'] == 'sample_random':
        cmd += ['--input-genes ${SOURCES[6]} --input-file ${SOURCES[7]}']
    else:
        cmd += ['--input-genes ${SOURCES[0]} --input-file ${SOURCES[1]}']

    return env.Command(
        [join(outdir, 'fitted_shazam.pkl'), join(outdir, 'log_shazam.txt')],
        c['generate_seqs'],
        ' '.join(map(str, cmd)))

# fit survival
@nest.add_target_with_env(localenv)
def fit_survival(env, outdir, c):
    cmd = []
    motif_len = MOTIF_LEN
    left_flanks = MUTATING_POSITION
    penalty_params = PENALTY_PARAMS

    cmd = ['python fit_context_model.py',
           '--seed',
           c['seed'],
           '--motif-lens',
           '3,5',
           '--positions-mutating',
           '1:2',
           '--penalty-params',
           PENALTY_PARAMS,
           '--num-cpu-threads',
           4,
           '--num-jobs',
           20,
           '--burn-in',
           2,
           '--num-e-samples',
           4,
           '--em-max-iters',
           10,
           '--num-val-burnin',
           2,
           '--num-val-samples',
           4,
           '--scratch-directory',
           SCRATCH_DIR,
           '--tuning-sample-ratio',
           0.1,
           '--omit-hessian',
           '--out-file ${TARGETS[0]}',
           '--log-file ${TARGETS[1]}',
           '--per-target-model']

    if c['data_type'] == 'true_ancestors':
        cmd += ['--input-genes ${SOURCES[2]} --input-seqs ${SOURCES[3]}']
    elif c['data_type'] == 'imputed_ancestors':
        cmd += ['--input-genes ${SOURCES[4]} --input-seqs ${SOURCES[5]}']
    elif c['data_type'] == 'sample_random':
        cmd += ['--input-genes ${SOURCES[6]} --input-seqs ${SOURCES[7]}']
    else:
        cmd += ['--input-genes ${SOURCES[0]} --input-seqs ${SOURCES[1]}']

    return env.Command(
        [join(outdir, 'fitted.pkl'), join(outdir, 'log.txt')],
        c['generate_seqs'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def convert_fit_shazam(env, outdir, c):

    def write_files(target, source, env):
        c = env['control']
        with open(str(source[0]), 'r') as f:
            theta_mut, (_, theta_sub) = pickle.load(f)

        feat_generator = HierarchicalMotifFeatureGenerator(motif_lens=[MOTIF_LEN])
        motif_list = feat_generator.motif_list

        columns = 'rep motif col theta data model'.split()
        data = []
        for col in range(5):
            for idx, motif in enumerate(motif_list):
                data_dict = {'rep': c['replicate'], 'motif': motif, 'col': col, 'data': c['data_type'], 'model': 'SHazaM'}
                if col == 0:
                    data_dict['theta'] = theta_mut.ravel()[idx]
                else:
                    data_dict['theta'] = theta_sub[idx, col - 1]

                data.append(data_dict)

        with open(str(target[0]), 'wb') as f:
            writer = csv.DictWriter(f, columns)
            writer.writeheader()
            writer.writerows(data)

    c['compare_models'].append(env.Command(
        join(outdir, 'fitted_shazam.csv'),
        c['fit_shazam'],
        write_files,
        control=c))

@nest.add_target_with_env(localenv)
def convert_fit_survival(env, outdir, c):

    def write_files(target, source, env):
        c = env['control']
        with open(str(source[0]), 'r') as f:
            fitted_models = pickle.load(f)
            best_model = pick_best_model(fitted_models)

        hier_feat_gen = HierarchicalMotifFeatureGenerator(
            motif_lens=best_model.motif_lens,
            feats_to_remove=best_model.model_masks.feats_to_remove,
            left_motif_flank_len_list=best_model.positions_mutating,
        )
        agg_feat_gen = HierarchicalMotifFeatureGenerator(
            motif_lens=[MOTIF_LEN],
            left_motif_flank_len_list=[[MUTATING_POSITION]],
        )
        theta = create_aggregate_theta(
            hier_feat_gen,
            agg_feat_gen,
            best_model.refit_theta,
            best_model.model_masks.zero_theta_mask_refit,
            best_model.refit_possible_theta_mask,
            keep_col0=True,
            add_targets=False,
        )

        motif_list = agg_feat_gen.motif_list

        columns = 'rep motif col theta data model'.split()
        data = []
        for col in range(5):
            for idx, motif in enumerate(motif_list):
                data_dict = {'rep': c['replicate'], 'motif': motif, 'col': col, 'data': c['data_type'], 'model': 'samm'}
                data_dict['theta'] = theta[idx, col]
                data.append(data_dict)

        with open(str(target[0]), 'wb') as f:
            writer = csv.DictWriter(f, columns)
            writer.writeheader()
            writer.writerows(data)

    c['compare_models'].append(env.Command(
        join(outdir, 'fitted_surv.csv'),
        c['fit_survival'],
        write_files,
        control=c))

nest.pop('data_type')

# concatenate into one file with parameter values and what type of data we obtained.
@nest.add_target_with_env(localenv)
def summarize(env, outdir, c):
    def cat_files(target, source, env):
        with open(str(target[0]), 'w') as catted_files:
            with open(str(source[0])) as first_file:
                # keep header from first file
                for line in first_file:
                    catted_files.write(line)

            for fname in source[1:]:
                with open(str(fname)) as next_file:
                    next(next_file)
                    for line in next_file:
                        catted_files.write(line)
    return env.Command(
        join(outdir, 'results.csv'),
        c['compare_models'],
        cat_files)

